{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67cbf0fe-e21a-486a-9f98-53f0452ce131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42fa28-0cbd-4297-846e-4658bbbb7f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n",
      "ds size in GB 8.14\n",
      "\n",
      "2002\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_year = 2001\n",
    "end_year = 2023\n",
    "\n",
    "def preprocess(ds):\n",
    "    latmin, latmax, lonmin, lonmax = 10., 70., -140., -80.\n",
    "    ds = ds.sel(lat=slice(latmin, latmax), lon=slice(lonmin, lonmax))\n",
    "    return ds\n",
    "\n",
    "for i, year in enumerate(np.arange(start_year, end_year+1)):\n",
    "    print(year)\n",
    "    ## create list of IVT filenames for the year plus month prior\n",
    "    start_date='{0}-12-01'.format(year-1) # we want December from the previous year\n",
    "    end_date='{0}-12-31'.format(year)\n",
    "\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='1MS')\n",
    "    # put into pandas df\n",
    "    d ={\"date\": dates}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    df['month']= df['date'].dt.month.map(\"{:02}\".format)\n",
    "    df['year']= df['date'].dt.year\n",
    "\n",
    "    # create list of daily ERA5 files for each AR\n",
    "    filenames = []\n",
    "    for j, row in df.iterrows():\n",
    "        filenames.append('/expanse/nfs/cw3e/cwp140/preprocessed/ERA5/ivt/{0}{1}_IVT.nc'.format(row['year'], row['month']))\n",
    "        \n",
    "    # open all files within the AR period\n",
    "    era = xr.open_mfdataset(filenames, combine='by_coords', preprocess=preprocess)\n",
    "    ds = era.compute()\n",
    "\n",
    "    ## compute duration of IVT >= 250.\n",
    "    AR = xr.where(ds.IVT >= 250, 1, 0)\n",
    "    a = AR != 0 # this will place True for all rows where AR is not 0\n",
    "    \n",
    "    # get the temporal resolution in hours\n",
    "    t = ds['time'].isel(time=1) - ds['time'].isel(time=0) \n",
    "    nhrs = t.values.astype('timedelta64[h]') # convert to hours\n",
    "    \n",
    "    ## this grabs the start and stop indices of each AR\n",
    "    tmp = a.cumsum()-a.cumsum().where(~a).ffill(dim='time').fillna(0).astype(int) # cumulative sum where not 0\n",
    "    duration = tmp*nhrs.astype(int)\n",
    "    duration = duration.rename(\"duration\")\n",
    "    # duration = duration.compute()\n",
    "    ds = xr.merge([ds, duration])\n",
    "\n",
    "    ## compute preliminary rank\n",
    "    pr1 = xr.where((ds.IVT >= 250.) & (ds.IVT < 500.), 1, np.nan)\n",
    "    pr2 = xr.where((ds.IVT >= 500.) & (ds.IVT < 750.), 2, np.nan)\n",
    "    pr3 = xr.where((ds.IVT >= 750.) & (ds.IVT < 1000.), 3, np.nan)\n",
    "    pr4 = xr.where((ds.IVT >= 1000.) & (ds.IVT < 1250.), 4, np.nan)\n",
    "    pr5 = xr.where((ds.IVT >= 1250.), 5, np.nan)\n",
    "    \n",
    "    prelim_rank = xr.merge([pr1, pr2, pr3, pr4, pr5], compat='no_conflicts')\n",
    "    prelim_rank = prelim_rank.rename({\"IVT\": \"prelim_rank\"})\n",
    "    # prelim_rank = prelim_rank.compute()\n",
    "    ## put into ds\n",
    "    ds = xr.merge([ds, prelim_rank])\n",
    "\n",
    "    ## compute final rank\n",
    "    rank24 = xr.where((ds.duration < 24.), ds.prelim_rank - 1, np.nan)\n",
    "    rank48 = xr.where((ds.duration >= 48.), ds.prelim_rank + 1, np.nan)\n",
    "    rank0 = xr.where((ds.duration >= 24.) & (ds.duration <48.), ds.prelim_rank, np.nan)\n",
    "    \n",
    "    rank = xr.merge([rank24.rename('rank'), rank48.rename('rank'), rank0.rename('rank')], compat='no_conflicts')\n",
    "    ds = xr.merge([ds, rank])\n",
    "    ds = ds.drop_vars([\"duration\", \"prelim_rank\"]) # drop unnecessary variables\n",
    "    ds = ds.sel(time=slice('{0}-01-01'.format(year), '{0}-12-31'.format(year))) # slice down to the current year\n",
    "    print('ds size in GB {:0.2f}\\n'.format(ds.nbytes / 1e9))\n",
    "    path_to_data = '/expanse/nfs/cw3e/cwp140/preprocessed/ARScale_ERA5/'\n",
    "    fname_out = path_to_data + 'ERA5_ARScale_{0}.nc'.format(year)\n",
    "    ds.to_netcdf(path=fname_out, mode = 'w', format='NETCDF4')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:UCRB-WY2023]",
   "language": "python",
   "name": "conda-env-UCRB-WY2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
